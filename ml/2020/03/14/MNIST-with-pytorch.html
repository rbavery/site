<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Buidling an MNIST Classifier from scratch with Pytorch | fastpages</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Buidling an MNIST Classifier from scratch with Pytorch" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A first post on making my way through fastbook" />
<meta property="og:description" content="A first post on making my way through fastbook" />
<link rel="canonical" href="ryanavery.rocks/ml/2020/03/14/MNIST-with-pytorch.html" />
<meta property="og:url" content="ryanavery.rocks/ml/2020/03/14/MNIST-with-pytorch.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:image" content="ryanavery.rocks/images/mnist_example.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-03-14T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"ryanavery.rocks/ml/2020/03/14/MNIST-with-pytorch.html","@type":"BlogPosting","headline":"Buidling an MNIST Classifier from scratch with Pytorch","dateModified":"2020-03-14T00:00:00-05:00","datePublished":"2020-03-14T00:00:00-05:00","image":"ryanavery.rocks/images/mnist_example.png","mainEntityOfPage":{"@type":"WebPage","@id":"ryanavery.rocks/ml/2020/03/14/MNIST-with-pytorch.html"},"description":"A first post on making my way through fastbook","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="ryanavery.rocks/feed.xml" title="fastpages" /><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">fastpages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Buidling an MNIST Classifier from scratch with Pytorch</h1><p class="page-description">A first post on making my way through fastbook</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-03-14T00:00:00-05:00" itemprop="datePublished">
        Mar 14, 2020
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      7 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#ml">ml</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/rbavery/site/tree/master/_notebooks/2020-03-14-MNIST-with-pytorch.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/rbavery/site/master?filepath=_notebooks%2F2020-03-14-MNIST-with-pytorch.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/rbavery/site/blob/master/_notebooks/2020-03-14-MNIST-with-pytorch.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-03-14-MNIST-with-pytorch.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I've been following Jermey Howard's and Sylvain Gugger's excellent preprint <a href="https://github.com/fastai/fastbook">fastbook</a>, their soon to be released book on deep learning and the new fastai2 API. While I've been practicing machine learning for land cover segmentation for a while now, I wanted a deeper understanding of the architectures I've been using. Chapter 4 provided an excellent walkthrough of building and evaluating a linear classifier and then a simple 3 layer neural network classifier of 3s and 7s. The final challenge after this chapter tasks the reader with the following:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote><h3 id="Further-research">Further research<a class="anchor-link" href="#Further-research"> </a></h3><ol>
<li>Create your own implementation of <code>Learner</code> from scratch, based on the training loop shown in this chapter.</li>
<li>Complete all the steps in this chapter using the full MNIST datasets (that is, for all digits, not just threes and sevens). This is a significant project and will take you quite a bit of time to complete! You'll need to do some of your own research to figure out how to overcome some obstacles you'll meet on the way.</li>
</ol>
</blockquote>
<p><a href="https://github.com/fastai/fastbook/blob/master/04_mnist_basics.ipynb">Source:Under the hood: training a digit classifier</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>After going through the Ch. 4 tutorial on building a binary classifier from scratch, I decided to jump straight to Challenge number 2 and complete it with functions. Below is the resulting code in case it's useful for anyone. Big thanks to Jeremy and Sebastian for their generosity in developing the book and fastai course and thanks to the pytorch community for taking the time to answer community questions <a href="https://discuss.pytorch.org/t/mnist-dataset-why-is-my-loss-so-high-beginner/62670">like this one</a>, which helped me troubleshoot my own issues.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Programming-environment-setup">Programming environment setup<a class="anchor-link" href="#Programming-environment-setup"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I used the <a href="https://github.com/NVIDIA/data-science-stack">nvidia-data-science-stack 2.2</a> to build a conda environment. This is a nifty tool that makes it easy to set up gpu dependencies. If you build a docker container, you don't need to mess around with installing nvidia drivers at all. Then I did development installs of fastai2 and fastcore (you can find them on github). You can run this whole tutorial on the cpu, it will take minutes rather than seconds compared to a gpu.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastai2.vision.all</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;image&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Greys&#39;</span><span class="p">)</span>

<span class="n">data_path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">MNIST</span><span class="p">)</span>

<span class="n">data_path</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(#2) [Path(&#39;/home/rave/.fastai/data/mnist_png/training&#39;),Path(&#39;/home/rave/.fastai/data/mnist_png/testing&#39;)]</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">(</span><span class="n">data_path</span><span class="o">/</span><span class="s2">&quot;training&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(#10) [Path(&#39;/home/rave/.fastai/data/mnist_png/training/5&#39;),Path(&#39;/home/rave/.fastai/data/mnist_png/training/9&#39;),Path(&#39;/home/rave/.fastai/data/mnist_png/training/6&#39;),Path(&#39;/home/rave/.fastai/data/mnist_png/training/7&#39;),Path(&#39;/home/rave/.fastai/data/mnist_png/training/2&#39;),Path(&#39;/home/rave/.fastai/data/mnist_png/training/8&#39;),Path(&#39;/home/rave/.fastai/data/mnist_png/training/4&#39;),Path(&#39;/home/rave/.fastai/data/mnist_png/training/1&#39;),Path(&#39;/home/rave/.fastai/data/mnist_png/training/3&#39;),Path(&#39;/home/rave/.fastai/data/mnist_png/training/0&#39;)]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="First-we-load-in-the-data">First we load in the data<a class="anchor-link" href="#First-we-load-in-the-data"> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">load_x_y</span><span class="p">(</span><span class="n">folder</span><span class="p">):</span>
    <span class="n">numtensors</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">labellists</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">9</span><span class="p">):</span>
        <span class="n">num_paths</span> <span class="o">=</span> <span class="p">(</span><span class="n">data_path</span><span class="o">/</span><span class="n">folder</span><span class="o">/</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">num</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span><span class="o">.</span><span class="n">sorted</span><span class="p">()</span>
        <span class="n">tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">tensor</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">n</span><span class="p">))</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">num_paths</span><span class="p">]</span>
        <span class="n">num_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">/</span><span class="mf">255.0</span>
        <span class="n">numtensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">num_tensor</span><span class="p">)</span>
        <span class="n">labellists</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">num</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">num_paths</span><span class="p">))</span>

    <span class="n">train_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">numtensors</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span> 
    <span class="c1"># list of vectors where each vector is an image. list is ordered from 0 samples to 9 samples</span>

    <span class="n">train_y</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">(</span><span class="n">labellists</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span>

<span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span> <span class="o">=</span> <span class="n">load_x_y</span><span class="p">(</span><span class="s2">&quot;training&quot;</span><span class="p">)</span>
<span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span> <span class="o">=</span> <span class="n">load_x_y</span><span class="p">(</span><span class="s2">&quot;testing&quot;</span><span class="p">)</span>
<span class="n">train_dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)),</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
<span class="n">test_dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span><span class="p">)),</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Each-image-is-reshaped-in-the-load_x_y-func-to-be-a-vector,-so-we-need-to-reshaped-it-with-.view-to-plot-it.">Each image is reshaped in the <code>load_x_y</code> func to be a vector, so we need to reshaped it with <code>.view</code> to plot it.<a class="anchor-link" href="#Each-image-is-reshaped-in-the-load_x_y-func-to-be-a-vector,-so-we-need-to-reshaped-it-with-.view-to-plot-it."> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">show_image</span><span class="p">(</span><span class="n">train_x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7fc6682e5610&gt;</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAD0ElEQVR4nO3aTUhUXxjH8Y8avpWECQlJVBhBK1u4LGo50CoqEaqFRAvpRYJKUNxILcRFFFFUuxDaRHvBTQraqhZRu+x9U0IRJYlR/4X/62WOwYzOHY04382FO/ee5/Cb3zznOc+Zit+/f4ukVK71BP42oiABUZCAKEhAFCRgXYHP/+UlqOJPN6NDAqIgAVGQgChIQBQkIAoSEAUJKFSHrDrv3r0D165dA1evXgXnz58HPT09YOvWrWWJHx0SUFGgH7JqleqHDx9AW1sb+PLlyx+fa2xsBJ8+fSo1ZKxUi+GvyCFv3rxx4MAB8PnzZ1BRsfAFbty4EdTU1ICPHz+C6elpsG3bNlBVVZXJXKJDAtYkh8zPz2PBGZDL5bx+/Xoh4P/zSRyyf/9+cOXKFbB379685+7cuQNOnjy53GnEHFIMa5JDLl68CG7cuFHw2UePHoHv37+DQ4cOgYcPH4KnT59mOrfokIBVdUhShY6MjCDNA6Tf/OHDh8Hx48eRVqS7d+8Gvb294MGDB0vGyILokIBVWWUKVaHHjh1z9+5d8OLFC/DkyRPQ2dkJ6uvr895J6o7169eD58+fY1l7nLjKFENZc8jMzAwYGhpCWoU2NzeDHTt2gO7ubtXV1WDPnj1510LMzs6C4eFhcP369ZLmHB0SUBaH/Pz5E1y4cAHpqpLsS0ZHR8HOnTuRVq6l8OrVq5LHIDpkCWVxyNu3b5E6I+Hx48dg165deffr6urKMY0VURZBTp8+jbRoSoquUIhS+PXrF6isrMyLVSrxJxOQqUOSjdb4+DjSLfzRo0ezDIPUGUmM9vb2bMbNZJR/iEwd8uPHDzA3Nwe2bNkCDh48WPLYyVIeFl5HjhwBfX19JccgOmQJZS3da2trwYYNG1Y8RuKMW7dugUuXLoHt27eD/v5+WCz9SyU6JKCsDjlx4sSK301aBsnG8ObNm6CrqwsW2wVZEx0SkGmDaHJyEuzbtw/p7/zly5dFj3H//n1w9uxZpC2Dc+fOIT38zoDYICqGTHNIUjUm1/fv34PBwUGkh0kNDQ1I2363b982MTEBiwdWra2tSFuIiUPKTXRIQKY5ZGpqCmkOCWlpaQGbNm0Cz549W/JMLpfLu545c2Y5U1gOMYcUQ6YO+fr1K+jo6ABjY2P5gwUH2QmbN2/W3d0NBgYGlhOyFKJDiqEsB1Xfvn0D9+7dQ7pChA65fPkyOHXqlKamppWEKoXokGL4a/50twZEhxRDFCQgChIQBQmIggREQQKiIAGF+iF/XKv/ZaJDAqIgAVGQgChIQBQkIAoS8B9vjSONi1qv3QAAAABJRU5ErkJggg==
" />
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">train_x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;/home/rave/site/images/mnist_example.png&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Below-are-the-components-of-our-network-and-training-plan.">Below are the components of our network and training plan.<a class="anchor-link" href="#Below-are-the-components-of-our-network-and-training-plan."> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">20</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span> <span class="c1"># step 6 define a stopping condition, the number of epochs in this case.</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">train_epoch</span><span class="p">(</span> <span class="n">model</span><span class="p">,</span> <span class="n">lr</span><span class="p">)</span> 
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loss for all MNIST classes Train: &quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total Test Accuracy For all MNIST classes: &quot;</span><span class="p">,</span> <span class="n">validate_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">))</span> <span class="c1"># step 5 calculate accuracy</span>

<span class="k">def</span> <span class="nf">validate_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">accs</span> <span class="o">=</span> <span class="p">[</span><span class="n">batch_accuracy</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">x_batch</span><span class="p">),</span> <span class="n">y_batch</span><span class="p">)</span> <span class="k">for</span> <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">test_dl</span><span class="p">]</span>
    <span class="k">return</span> <span class="nb">round</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">accs</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="mi">4</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">batch_accuracy</span><span class="p">(</span><span class="n">prediction_batch</span><span class="p">,</span> <span class="n">label_batch</span><span class="p">):</span>
    <span class="n">prob_scores</span> <span class="o">=</span> <span class="n">prediction_batch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># gets final activations into range of 0,1 so that all add up to 1</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">get_num_correct</span><span class="p">(</span><span class="n">prob_scores</span><span class="p">,</span> <span class="n">label_batch</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span> <span class="n">label_batch</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="p">)</span> <span class="c1"># sum the right predictions, divide by total number of isntances</span>
    <span class="k">return</span> <span class="n">accuracy</span>

<span class="k">def</span> <span class="nf">get_num_correct</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">preds</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="c1"># labels needs to be a 1d tensor for this comparison for broadcasting</span>
        
<span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lr</span><span class="p">):</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ys</span> <span class="ow">in</span> <span class="n">train_dl</span><span class="p">:</span> <span class="c1"># step 4 continue another forward pass and repeat for another epoch</span>
        <span class="c1"># calcualtes the gradient with respect to weight and bias params at each layer of the model</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">calc_grad</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
            <span class="c1"># modifies params in place, step 3 update the params (this  uses the backprop calculated gradient)</span>
            <span class="n">p</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">data</span> <span class="o">-</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="o">*</span> <span class="n">lr</span>
            <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
        <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="c1"># step 2 calculate gradient</span>
<span class="k">def</span> <span class="nf">calc_grad</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">):</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_batch</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">loss</span>
        
<span class="k">def</span> <span class="nf">linear_layer</span><span class="p">(</span><span class="n">xb</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">xb</span><span class="nd">@ws</span> <span class="o">+</span> <span class="n">bs</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="First-step-is-to-initialize-random-weights">First step is to initialize random weights<a class="anchor-link" href="#First-step-is-to-initialize-random-weights"> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">init_params</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span> <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="p">)</span><span class="o">*</span><span class="n">std</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>

<span class="n">ws</span> <span class="o">=</span> <span class="n">init_params</span><span class="p">((</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>

<span class="n">bs</span> <span class="o">=</span> <span class="n">init_params</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>

<span class="n">params</span> <span class="o">=</span> <span class="n">ws</span><span class="p">,</span> <span class="n">bs</span>

<span class="n">lr</span> <span class="o">=</span> <span class="mf">1.0</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">validate_epoch</span><span class="p">(</span><span class="n">linear_layer</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0.1255</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="mf">1.</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">ws</span><span class="p">,</span> <span class="n">bs</span>
<span class="n">train_epoch</span><span class="p">(</span><span class="n">linear_layer</span><span class="p">,</span> <span class="n">lr</span><span class="p">)</span>
<span class="n">validate_epoch</span><span class="p">(</span><span class="n">linear_layer</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0.1684</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Our-accuracy-improves!-We-can-now-train-a-full-model-with-multiple-epochs.">Our accuracy improves! We can now train a full model with multiple epochs.<a class="anchor-link" href="#Our-accuracy-improves!-We-can-now-train-a-full-model-with-multiple-epochs."> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_model</span><span class="p">(</span><span class="n">linear_layer</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Loss for all MNIST classes Train:  tensor(0.6126)
Total Test Accuracy For all MNIST classes:  0.2942
Loss for all MNIST classes Train:  tensor(0.4020)
Total Test Accuracy For all MNIST classes:  0.3543
Loss for all MNIST classes Train:  tensor(0.3152)
Total Test Accuracy For all MNIST classes:  0.3799
Loss for all MNIST classes Train:  tensor(0.2817)
Total Test Accuracy For all MNIST classes:  0.3963
Loss for all MNIST classes Train:  tensor(0.2605)
Total Test Accuracy For all MNIST classes:  0.4109
Loss for all MNIST classes Train:  tensor(0.2467)
Total Test Accuracy For all MNIST classes:  0.4248
Loss for all MNIST classes Train:  tensor(0.2371)
Total Test Accuracy For all MNIST classes:  0.4374
Loss for all MNIST classes Train:  tensor(0.2295)
Total Test Accuracy For all MNIST classes:  0.4455
Loss for all MNIST classes Train:  tensor(0.2229)
Total Test Accuracy For all MNIST classes:  0.454
Loss for all MNIST classes Train:  tensor(0.2170)
Total Test Accuracy For all MNIST classes:  0.463
Loss for all MNIST classes Train:  tensor(0.2114)
Total Test Accuracy For all MNIST classes:  0.4702
Loss for all MNIST classes Train:  tensor(0.2061)
Total Test Accuracy For all MNIST classes:  0.4765
Loss for all MNIST classes Train:  tensor(0.2010)
Total Test Accuracy For all MNIST classes:  0.4799
Loss for all MNIST classes Train:  tensor(0.1962)
Total Test Accuracy For all MNIST classes:  0.4833
Loss for all MNIST classes Train:  tensor(0.1918)
Total Test Accuracy For all MNIST classes:  0.4856
Loss for all MNIST classes Train:  tensor(0.1876)
Total Test Accuracy For all MNIST classes:  0.4896
Loss for all MNIST classes Train:  tensor(0.1837)
Total Test Accuracy For all MNIST classes:  0.4913
Loss for all MNIST classes Train:  tensor(0.1802)
Total Test Accuracy For all MNIST classes:  0.4945
Loss for all MNIST classes Train:  tensor(0.1770)
Total Test Accuracy For all MNIST classes:  0.4961
Loss for all MNIST classes Train:  tensor(0.1740)
Total Test Accuracy For all MNIST classes:  0.4978
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Much-of-the-above-code-can-be-compressed-down-to-the-following-code-chunk-using-fastai,-plus-I'm-testing-a-simple-2-(3?)-layer-net-instead-of-a-simpler-linear-model.">Much of the above code can be compressed down to the following code chunk using fastai, plus I'm testing a simple 2 (3?) layer net instead of a simpler linear model.<a class="anchor-link" href="#Much-of-the-above-code-can-be-compressed-down-to-the-following-code-chunk-using-fastai,-plus-I'm-testing-a-simple-2-(3?)-layer-net-instead-of-a-simpler-linear-model."> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">DataLoaders</span><span class="p">(</span><span class="n">train_dl</span><span class="p">,</span> <span class="n">test_dl</span><span class="p">)</span>
<span class="n">simple_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span><span class="mi">30</span><span class="p">),</span> <span class="c1"># 28*28 is shape of image input</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="c1"># 10 classes, 10 ending neurons</span>
<span class="p">)</span>
<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">simple_net</span><span class="p">,</span> <span class="n">opt_func</span><span class="o">=</span><span class="n">SGD</span><span class="p">,</span>
                <span class="n">loss_func</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">batch_accuracy</span><span class="p">)</span>

<span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="o">.</span><span class="mi">01</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>batch_accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.477771</td>
      <td>2.973853</td>
      <td>0.108331</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.943950</td>
      <td>2.823479</td>
      <td>0.109776</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.689013</td>
      <td>2.432964</td>
      <td>0.175064</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.551735</td>
      <td>2.100434</td>
      <td>0.299855</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.472151</td>
      <td>1.843670</td>
      <td>0.385163</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.420042</td>
      <td>1.648977</td>
      <td>0.432432</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.383341</td>
      <td>1.498606</td>
      <td>0.476365</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.356098</td>
      <td>1.379916</td>
      <td>0.515071</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.335129</td>
      <td>1.284503</td>
      <td>0.550328</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.318766</td>
      <td>1.206264</td>
      <td>0.577021</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>10</td>
      <td>0.305560</td>
      <td>1.141383</td>
      <td>0.598042</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>11</td>
      <td>0.294642</td>
      <td>1.086604</td>
      <td>0.616950</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>12</td>
      <td>0.285455</td>
      <td>1.039767</td>
      <td>0.635080</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>13</td>
      <td>0.277556</td>
      <td>0.999074</td>
      <td>0.650206</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>14</td>
      <td>0.270682</td>
      <td>0.963757</td>
      <td>0.660883</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>15</td>
      <td>0.264624</td>
      <td>0.932953</td>
      <td>0.672895</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>16</td>
      <td>0.259144</td>
      <td>0.906086</td>
      <td>0.682905</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>17</td>
      <td>0.254295</td>
      <td>0.882171</td>
      <td>0.690802</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>18</td>
      <td>0.249852</td>
      <td>0.860789</td>
      <td>0.700589</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>19</td>
      <td>0.245791</td>
      <td>0.841390</td>
      <td>0.706818</td>
      <td>00:00</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Adding-a-relu-and-another-linear-layer-gets-us-an-increase-in-accuracy-from-about-50%-to-70%-with-the-same-number-of-epochs-(try-training-for-longer-and-with-different-numbers-of-neurons-in-the-first-linear-layer,-which-makes-a-bigger-difference)?">Adding a relu and another linear layer gets us an increase in accuracy from about 50% to 70% with the same number of epochs (try training for longer and with different numbers of neurons in the first linear layer, which makes a bigger difference)?<a class="anchor-link" href="#Adding-a-relu-and-another-linear-layer-gets-us-an-increase-in-accuracy-from-about-50%-to-70%-with-the-same-number-of-epochs-(try-training-for-longer-and-with-different-numbers-of-neurons-in-the-first-linear-layer,-which-makes-a-bigger-difference)?"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Some issues I ran into include:</p>
<ul>
<li>multilabel softmax loss wasn't working, not sure why it wasn't the right loss function, but cross entropy worked after I set the weights and bias shapes so that the last dimension was 10 for the 10 "probability" scores for each digit.</li>
<li>I also had to find broadcasting errors. My accuracy was increasing above 1 until I found that the y_labels in <code>batch_accuracy</code> need to be a 1D tensor when doing comparisons with argmax. I had called <code>unsqueeze</code> in <code>load_x_y</code> on these label arrays which added an extra dimension that caused the broadcasting issue.</li>
<li>I kept running into cases where my loss was decreasing but my accuracy stayed the same, probably having to do with messy jupyter notebook state.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/images/copied_from_nb/../images/thats_all_folks.gif" alt="" /></p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="rbavery/site"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/ml/2020/03/14/MNIST-with-pytorch.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/rbavery" title="rbavery"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/rybavery" title="rybavery"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
