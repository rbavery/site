{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Buidling an MNIST Classifier from scratch with Pytorch\"\n",
    "> \"A first post on making my way through fastbook\"\n",
    "- toc: false\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [ml]\n",
    "- image: ../images/mnist_example.png\n",
    "- hide: false\n",
    "- showtags: true\n",
    "- search_exclude: false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've been following Jermey Howard's and Sylvain Gugger's excellent preprint [fastbook](https://github.com/fastai/fastbook), their soon to be released book on deep learning and the new fastai2 API. While I've been practicing machine learning for land cover segmentation for a while now, I wanted a deeper understanding of the architectures I've been using. Chapter 4 provided an excellent walkthrough of building and evaluating a linear classifier and then a simple 3 layer neural network classifier of 3s and 7s. The final challenge after this chapter tasks the reader with the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Further research\n",
    "\n",
    "> 1. Create your own implementation of `Learner` from scratch, based on the training loop shown in this chapter.\n",
    "> 1. Complete all the steps in this chapter using the full MNIST datasets (that is, for all digits, not just threes and sevens). This is a significant project and will take you quite a bit of time to complete! You'll need to do some of your own research to figure out how to overcome some obstacles you'll meet on the way.\n",
    "\n",
    "[Source: Under the hood: training a digit classifier](https://github.com/fastai/fastbook/blob/master/04_mnist_basics.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After going through the Ch. 4 tutorial on building a binary classifier from scratch, I decided to jump straight to Challenge number 2 and complete it with functions. Below is the resulting code in case it's useful for anyone. Big thanks to Jeremy and Sebastian for their generosity in developing the book and fastai course and thanks to the pytorch community for taking the time to answer community questions [like this one](https://discuss.pytorch.org/t/mnist-dataset-why-is-my-loss-so-high-beginner/62670), which helped me troubleshoot my own issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programming environment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the [nvidia-data-science-stack 2.2](https://github.com/NVIDIA/data-science-stack) to build a conda environment. This is a nifty tool that makes it easy to set up gpu dependencies. If you build a docker container, you don't need to mess around with installing nvidia drivers at all. Then I did development installs of fastai2 and fastcore (you can find them on github). You can run this whole tutorial on the cpu, it will take minutes rather than seconds compared to a gpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/home/rave/.fastai/data/mnist_png/training'),Path('/home/rave/.fastai/data/mnist_png/testing')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai2.vision.all import *\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')\n",
    "\n",
    "data_path = untar_data(URLs.MNIST)\n",
    "\n",
    "data_path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) [Path('/home/rave/.fastai/data/mnist_png/training/5'),Path('/home/rave/.fastai/data/mnist_png/training/9'),Path('/home/rave/.fastai/data/mnist_png/training/6'),Path('/home/rave/.fastai/data/mnist_png/training/7'),Path('/home/rave/.fastai/data/mnist_png/training/2'),Path('/home/rave/.fastai/data/mnist_png/training/8'),Path('/home/rave/.fastai/data/mnist_png/training/4'),Path('/home/rave/.fastai/data/mnist_png/training/1'),Path('/home/rave/.fastai/data/mnist_png/training/3'),Path('/home/rave/.fastai/data/mnist_png/training/0')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_path/\"training\").ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_x_y(folder):\n",
    "    numtensors = []\n",
    "    labellists = []\n",
    "    for num in range(9):\n",
    "        num_paths = (data_path/folder/f'{num}').ls().sorted()\n",
    "        tensors = [tensor(Image.open(n)) for n in num_paths]\n",
    "        num_tensor = torch.stack(tensors).float()/255.0\n",
    "        numtensors.append(num_tensor)\n",
    "        labellists.extend([num]*len(num_paths))\n",
    "\n",
    "    train_x = torch.cat(numtensors).view(-1, 28*28) \n",
    "    # list of vectors where each vector is an image. list is ordered from 0 samples to 9 samples\n",
    "\n",
    "    train_y = tensor(labellists)\n",
    "    \n",
    "    return train_x, train_y\n",
    "\n",
    "train_x, train_y = load_x_y(\"training\")\n",
    "test_x, test_y = load_x_y(\"testing\")\n",
    "train_dl = DataLoader(list(zip(train_x, train_y)), batch_size=256)\n",
    "test_dl = DataLoader(list(zip(test_x, test_y)), batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each image is reshaped in the `load_x_y` func to be a vector, so we need to reshaped it with `.view` to plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc6682e5610>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAD0ElEQVR4nO3aTUhUXxjH8Y8avpWECQlJVBhBK1u4LGo50CoqEaqFRAvpRYJKUNxILcRFFFFUuxDaRHvBTQraqhZRu+x9U0IRJYlR/4X/62WOwYzOHY04382FO/ee5/Cb3zznOc+Zit+/f4ukVK71BP42oiABUZCAKEhAFCRgXYHP/+UlqOJPN6NDAqIgAVGQgChIQBQkIAoSEAUJKFSHrDrv3r0D165dA1evXgXnz58HPT09YOvWrWWJHx0SUFGgH7JqleqHDx9AW1sb+PLlyx+fa2xsBJ8+fSo1ZKxUi+GvyCFv3rxx4MAB8PnzZ1BRsfAFbty4EdTU1ICPHz+C6elpsG3bNlBVVZXJXKJDAtYkh8zPz2PBGZDL5bx+/Xoh4P/zSRyyf/9+cOXKFbB379685+7cuQNOnjy53GnEHFIMa5JDLl68CG7cuFHw2UePHoHv37+DQ4cOgYcPH4KnT59mOrfokIBVdUhShY6MjCDNA6Tf/OHDh8Hx48eRVqS7d+8Gvb294MGDB0vGyILokIBVWWUKVaHHjh1z9+5d8OLFC/DkyRPQ2dkJ6uvr895J6o7169eD58+fY1l7nLjKFENZc8jMzAwYGhpCWoU2NzeDHTt2gO7ubtXV1WDPnj1510LMzs6C4eFhcP369ZLmHB0SUBaH/Pz5E1y4cAHpqpLsS0ZHR8HOnTuRVq6l8OrVq5LHIDpkCWVxyNu3b5E6I+Hx48dg165deffr6urKMY0VURZBTp8+jbRoSoquUIhS+PXrF6isrMyLVSrxJxOQqUOSjdb4+DjSLfzRo0ezDIPUGUmM9vb2bMbNZJR/iEwd8uPHDzA3Nwe2bNkCDh48WPLYyVIeFl5HjhwBfX19JccgOmQJZS3da2trwYYNG1Y8RuKMW7dugUuXLoHt27eD/v5+WCz9SyU6JKCsDjlx4sSK301aBsnG8ObNm6CrqwsW2wVZEx0SkGmDaHJyEuzbtw/p7/zly5dFj3H//n1w9uxZpC2Dc+fOIT38zoDYICqGTHNIUjUm1/fv34PBwUGkh0kNDQ1I2363b982MTEBiwdWra2tSFuIiUPKTXRIQKY5ZGpqCmkOCWlpaQGbNm0Cz549W/JMLpfLu545c2Y5U1gOMYcUQ6YO+fr1K+jo6ABjY2P5gwUH2QmbN2/W3d0NBgYGlhOyFKJDiqEsB1Xfvn0D9+7dQ7pChA65fPkyOHXqlKamppWEKoXokGL4a/50twZEhxRDFCQgChIQBQmIggREQQKiIAGF+iF/XKv/ZaJDAqIgAVGQgChIQBQkIAoS8B9vjSONi1qv3QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(train_x[0].view(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_x[0].view(28,28))\n",
    "plt.savefig(\"/home/rave/site/images/mnist_example.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are the components of our network and training plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, lr=1, epochs = 20):\n",
    "    for i in range(epochs): # step 6 define a stopping condition, the number of epochs in this case.\n",
    "        loss = train_epoch( model, lr) \n",
    "        print(\"Loss for all MNIST classes Train: \", loss)\n",
    "        print(\"Total Test Accuracy For all MNIST classes: \", validate_epoch(model)) # step 5 calculate accuracy\n",
    "\n",
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(x_batch), y_batch) for x_batch, y_batch in test_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)\n",
    "\n",
    "def batch_accuracy(prediction_batch, label_batch):\n",
    "    prob_scores = prediction_batch.softmax(1) # gets final activations into range of 0,1 so that all add up to 1\n",
    "    accuracy = get_num_correct(prob_scores, label_batch) / float( label_batch.size(0) ) # sum the right predictions, divide by total number of isntances\n",
    "    return accuracy\n",
    "\n",
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().float() # labels needs to be a 1d tensor for this comparison for broadcasting\n",
    "        \n",
    "def train_epoch(model, lr):\n",
    "    losses = []\n",
    "    for xs, ys in train_dl: # step 4 continue another forward pass and repeat for another epoch\n",
    "        # calcualtes the gradient with respect to weight and bias params at each layer of the model\n",
    "        loss = calc_grad(xs, ys, model)\n",
    "        for p in params:\n",
    "            # modifies params in place, step 3 update the params (this  uses the backprop calculated gradient)\n",
    "            p.data = p.data - p.grad * lr\n",
    "            p.grad.zero_()\n",
    "        losses.append(loss.detach())\n",
    "    return torch.stack(losses).mean()\n",
    "\n",
    "# step 2 calculate gradient\n",
    "def calc_grad(x_batch, y_batch, model, loss_func=F.cross_entropy):\n",
    "    predictions = model(x_batch)\n",
    "    loss = loss_func(predictions, y_batch)\n",
    "    loss.backward()\n",
    "    return loss\n",
    "        \n",
    "def linear_layer(xb):\n",
    "    return xb@ws + bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First step is to initialize random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()\n",
    "\n",
    "ws = init_params((28*28,10))\n",
    "\n",
    "bs = init_params(10)\n",
    "\n",
    "params = ws, bs\n",
    "\n",
    "lr = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1255"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1684"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1.\n",
    "params = ws, bs\n",
    "train_epoch(linear_layer, lr)\n",
    "validate_epoch(linear_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our accuracy improves! We can now train a full model with multiple epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for all MNIST classes Train:  tensor(0.6126)\n",
      "Total Test Accuracy For all MNIST classes:  0.2942\n",
      "Loss for all MNIST classes Train:  tensor(0.4020)\n",
      "Total Test Accuracy For all MNIST classes:  0.3543\n",
      "Loss for all MNIST classes Train:  tensor(0.3152)\n",
      "Total Test Accuracy For all MNIST classes:  0.3799\n",
      "Loss for all MNIST classes Train:  tensor(0.2817)\n",
      "Total Test Accuracy For all MNIST classes:  0.3963\n",
      "Loss for all MNIST classes Train:  tensor(0.2605)\n",
      "Total Test Accuracy For all MNIST classes:  0.4109\n",
      "Loss for all MNIST classes Train:  tensor(0.2467)\n",
      "Total Test Accuracy For all MNIST classes:  0.4248\n",
      "Loss for all MNIST classes Train:  tensor(0.2371)\n",
      "Total Test Accuracy For all MNIST classes:  0.4374\n",
      "Loss for all MNIST classes Train:  tensor(0.2295)\n",
      "Total Test Accuracy For all MNIST classes:  0.4455\n",
      "Loss for all MNIST classes Train:  tensor(0.2229)\n",
      "Total Test Accuracy For all MNIST classes:  0.454\n",
      "Loss for all MNIST classes Train:  tensor(0.2170)\n",
      "Total Test Accuracy For all MNIST classes:  0.463\n",
      "Loss for all MNIST classes Train:  tensor(0.2114)\n",
      "Total Test Accuracy For all MNIST classes:  0.4702\n",
      "Loss for all MNIST classes Train:  tensor(0.2061)\n",
      "Total Test Accuracy For all MNIST classes:  0.4765\n",
      "Loss for all MNIST classes Train:  tensor(0.2010)\n",
      "Total Test Accuracy For all MNIST classes:  0.4799\n",
      "Loss for all MNIST classes Train:  tensor(0.1962)\n",
      "Total Test Accuracy For all MNIST classes:  0.4833\n",
      "Loss for all MNIST classes Train:  tensor(0.1918)\n",
      "Total Test Accuracy For all MNIST classes:  0.4856\n",
      "Loss for all MNIST classes Train:  tensor(0.1876)\n",
      "Total Test Accuracy For all MNIST classes:  0.4896\n",
      "Loss for all MNIST classes Train:  tensor(0.1837)\n",
      "Total Test Accuracy For all MNIST classes:  0.4913\n",
      "Loss for all MNIST classes Train:  tensor(0.1802)\n",
      "Total Test Accuracy For all MNIST classes:  0.4945\n",
      "Loss for all MNIST classes Train:  tensor(0.1770)\n",
      "Total Test Accuracy For all MNIST classes:  0.4961\n",
      "Loss for all MNIST classes Train:  tensor(0.1740)\n",
      "Total Test Accuracy For all MNIST classes:  0.4978\n"
     ]
    }
   ],
   "source": [
    "train_model(linear_layer, lr=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Much of the above code can be compressed down to the following code chunk using fastai, plus I'm testing a simple 2 (3?) layer net instead of a simpler linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.477771</td>\n",
       "      <td>2.973853</td>\n",
       "      <td>0.108331</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.943950</td>\n",
       "      <td>2.823479</td>\n",
       "      <td>0.109776</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.689013</td>\n",
       "      <td>2.432964</td>\n",
       "      <td>0.175064</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.551735</td>\n",
       "      <td>2.100434</td>\n",
       "      <td>0.299855</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.472151</td>\n",
       "      <td>1.843670</td>\n",
       "      <td>0.385163</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.420042</td>\n",
       "      <td>1.648977</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.383341</td>\n",
       "      <td>1.498606</td>\n",
       "      <td>0.476365</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.356098</td>\n",
       "      <td>1.379916</td>\n",
       "      <td>0.515071</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.335129</td>\n",
       "      <td>1.284503</td>\n",
       "      <td>0.550328</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.318766</td>\n",
       "      <td>1.206264</td>\n",
       "      <td>0.577021</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.305560</td>\n",
       "      <td>1.141383</td>\n",
       "      <td>0.598042</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.294642</td>\n",
       "      <td>1.086604</td>\n",
       "      <td>0.616950</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.285455</td>\n",
       "      <td>1.039767</td>\n",
       "      <td>0.635080</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.277556</td>\n",
       "      <td>0.999074</td>\n",
       "      <td>0.650206</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.270682</td>\n",
       "      <td>0.963757</td>\n",
       "      <td>0.660883</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.264624</td>\n",
       "      <td>0.932953</td>\n",
       "      <td>0.672895</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.259144</td>\n",
       "      <td>0.906086</td>\n",
       "      <td>0.682905</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.254295</td>\n",
       "      <td>0.882171</td>\n",
       "      <td>0.690802</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.249852</td>\n",
       "      <td>0.860789</td>\n",
       "      <td>0.700589</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.245791</td>\n",
       "      <td>0.841390</td>\n",
       "      <td>0.706818</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = DataLoaders(train_dl, test_dl)\n",
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28,30), # 28*28 is shape of image input\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30, 10) # 10 classes, 10 ending neurons\n",
    ")\n",
    "learn = Learner(dls, simple_net, opt_func=SGD,\n",
    "                loss_func=F.cross_entropy, metrics=batch_accuracy)\n",
    "\n",
    "learn.fit(20, .01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a relu and another linear layer gets us an increase in accuracy from about 50% to 70% with the same number of epochs (try training for longer and with different numbers of neurons in the first linear layer, which makes a bigger difference)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some issues I ran into include:\n",
    "\n",
    "* multilabel softmax loss wasn't working, not sure why it wasn't the right loss function, but cross entropy worked after I set the weights and bias shapes so that the last dimension was 10 for the 10 \"probability\" scores for each digit.\n",
    "* I also had to find broadcasting errors. My accuracy was increasing above 1 until I found that the y_labels in `batch_accuracy` need to be a 1D tensor when doing comparisons with argmax. I had called `unsqueeze` in `load_x_y` on these label arrays which added an extra dimension that caused the broadcasting issue.\n",
    "* I kept running into cases where my loss was decreasing but my accuracy stayed the same, probably having to do with messy jupyter notebook state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/thats_all_folks.gif)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
